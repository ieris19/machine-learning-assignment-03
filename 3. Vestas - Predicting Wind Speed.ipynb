{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Wind data analysis\n",
    "\n",
    "For this project, we will be working with the Risø dataset. The data can be found \n",
    "[here](https://data.dtu.dk/articles/dataset/Wind_resource_data_from_the_tall_Ris_met_mast/14153204).\n",
    "\n",
    "Before we can start, we must first load all the libraries we will be using in\n",
    "this notebook so that others can easily see a list of all packages needed to \n",
    "run the code in this notebook. \n",
    "\n",
    "After importing all the necessary libraries, we must then prepare the data for\n",
    "analysis, this means loading the data, cleaning it and checking for any mistakes\n",
    "or missing data.\n",
    "\n",
    "Finally, we will proceed with the rest of the assignment."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Definitions\n",
    "Before we actually process the data, we must define what files we're working with.\n",
    "These variables can be changed to work with different datasets as long as the \n",
    "data is in a similar format. For example, they can be changed to work with the\n",
    "Børglum dataset if needed. These variables are all that would need to be changed.\n",
    "\n",
    "To bear in mind: The notebook assumes that the provided signals are in the same\n",
    "order, so, if replacing these variables make sure the signals are at the same\n",
    "index (e.g. the second signal in the list must be the wind speed, etc...)."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "meso_file = 'data/risoe/meso_Risoe.csv'\n",
    "mast_file = 'data/risoe/risoe_m_all.nc'\n",
    "\n",
    "meso_signals = ['TIMESTAMP', 'WSP080', 'WDIR080']\n",
    "mast_signals = ['time', 'ws77', 'wd77']\n",
    "\n",
    "base_date = datetime(1995, 11, 20, 16, 25, 0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data Preprocessing\n",
    "We will start by loading the necessary data and preparing to work with it.\n",
    "\n",
    "For this, we need both the mast data and the meso data. We will only be considering\n",
    "the wind speed and its direction for this assignment. There are other indicators\n",
    "that we consider have a negligible impact in the decision of the wind turbine\n",
    "placement.\n",
    "\n",
    "Since we have multiple signals to choose from, we've selected the following to\n",
    "work with in this assignment:\n",
    "- Mast:\n",
    "    - Wind Speead at an altitude of 77m\n",
    "    - Wind Direction at an altitude of 77m\n",
    "- Meso:\n",
    "    - Wind Speed at an altitude of 80m\n",
    "    - Wind Direction at an altitude of 80m\n",
    "\n",
    "These signals are as close to each other as possible so we believe the difference\n",
    "in altitude will not have a significant impact in the data, it's only a 3m difference.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Defining a function that splices the data into the necessary columns\n",
    "def preprocessing_data(data, time_signal, speed_signal, direction_signal):\n",
    "    df = pd.DataFrame()\n",
    "    df['TIMESTAMP'] = pd.to_datetime(data[time_signal])\n",
    "    df['SPEED'] = data[speed_signal]\n",
    "    df['DIRECTION'] = data[direction_signal]\n",
    "    direction_radians = np.radians(df['DIRECTION'])\n",
    "    df['u'] = np.sin(direction_radians)\n",
    "    df['v'] = np.cos(direction_radians)\n",
    "    df = df.resample('1h', on='TIMESTAMP').mean()\n",
    "    df['DIRECTION'] = (np.degrees(np.arctan2(df['u'], df['v'])) + 360) % 360\n",
    "    df = df.resample('1h').asfreq(1).reset_index()\n",
    "    return df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "meso_set = pd.read_csv(meso_file)[meso_signals]\n",
    "\n",
    "# meso_timeframe = pd.to_datetime(meso_set['TIMESTAMP'])\n",
    "# display(meso_set[['TIMESTAMP', meso_signals[1]]])\n",
    "meso_data = preprocessing_data(meso_set, meso_signals[0], meso_signals[1], meso_signals[2])\n",
    "\n",
    "print(meso_data['DIRECTION'].min(), meso_data['DIRECTION'].max())\n",
    "print(meso_data['SPEED'].min(), meso_data['SPEED'].max())\n",
    "meso_data"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mast_set = nc.Dataset(mast_file, 'r')\n",
    "\n",
    "time = []\n",
    "for minutes in np.array(mast_set.variables[mast_signals[0]]):\n",
    "    time_delta = timedelta(minutes=int(minutes))\n",
    "    timestamp = base_date + time_delta\n",
    "    time.append(timestamp)    \n",
    "mast_df = pd.DataFrame()\n",
    "mast_df['TIMESTAMP'] = time\n",
    "mast_df['SPEED'] = np.array(mast_set.variables[mast_signals[1]])\n",
    "mast_df['DIRECTION'] = np.array(mast_set.variables[mast_signals[2]])\n",
    "\n",
    "mast_data = preprocessing_data(mast_df, 'TIMESTAMP', 'SPEED', 'DIRECTION')\n",
    "\n",
    "print(mast_data['TIMESTAMP'].min(), mast_data['TIMESTAMP'].max())\n",
    "mast_data"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mast_data = mast_data.dropna().reset_index()\n",
    "meso_data = meso_data.dropna().reset_index()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Because there is some periodicity to the wind, we can add some features to help the model make better predictions\n",
    "meso_data['HOUR_SIN'] = np.sin(2 * np.pi * meso_data['TIMESTAMP'].dt.hour / 24)\n",
    "meso_data['HOUR_COS'] = np.cos(2 * np.pi * meso_data['TIMESTAMP'].dt.hour / 24)\n",
    "meso_data['DAY_SIN'] = np.sin(2 * np.pi * meso_data['TIMESTAMP'].dt.dayofyear / 365)\n",
    "meso_data['DAY_COS'] = np.cos(2 * np.pi * meso_data['TIMESTAMP'].dt.dayofyear / 365)\n",
    "\n",
    "# We convert the mast data to UTC time\n",
    "if 'time_utc' in mast_data.columns:\n",
    "    mast_data.drop(columns=['TIMESTAMP_UTC'], inplace=True)\n",
    "mast_data.insert(1, 'TIMESTAMP_UTC', mast_data['TIMESTAMP'] - pd.Timedelta(hours=1))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check for unique years in the data\n",
    "mast_data_years = mast_data['TIMESTAMP'].dt.year.unique()\n",
    "meso_data_years = meso_data['TIMESTAMP'].dt.year.unique()\n",
    "print(mast_data_years)\n",
    "print(meso_data_years)\n",
    "# Calculate the intersection of the two year ranges\n",
    "overlap = np.intersect1d(mast_data_years, meso_data_years)\n",
    "print(overlap)\n",
    "\n",
    "mast_data = mast_data[mast_data['TIMESTAMP'].dt.year.isin(overlap)].reset_index()\n",
    "meso_data = meso_data[meso_data['TIMESTAMP'].dt.year.isin(overlap)].reset_index()\n",
    "display(mast_data, meso_data)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# We can now merge the data into our final dataset\n",
    "dataset = pd.merge(meso_data, mast_data, left_on='TIMESTAMP', right_on='TIMESTAMP_UTC', how='inner', suffixes=('_meso', '_mast'))\n",
    "print('corr utc:', dataset['SPEED_mast'].corr(dataset['SPEED_meso']))\n",
    "dataset = dataset.drop(columns=['TIMESTAMP_meso', 'level_0_meso', 'level_0_mast', 'index_mast', 'index_meso', 'TIMESTAMP_mast'])\n",
    "dataset"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# We can now finally split the data and train a model\n",
    "X = dataset[['SPEED_meso', 'DIRECTION_meso', 'HOUR_SIN', 'HOUR_COS', 'DAY_SIN', 'DAY_COS']].copy()\n",
    "y = dataset[['SPEED_mast', 'u_mast', 'v_mast']].copy()\n",
    "\n",
    "idx = int(len(dataset) * 0.8)\n",
    "X_train, y_train, X_test, y_test = X[:idx], y[:idx], X[idx:], y[idx:]\n",
    "\n",
    "X_scaler = StandardScaler()\n",
    "X_train = X_scaler.fit_transform(X_train)\n",
    "X_test = X_scaler.transform(X_test)\n",
    "y_scaler = StandardScaler()\n",
    "y_train = y_scaler.fit_transform(y_train)\n",
    "y_test = y_scaler.transform(y_test)\n",
    "\n",
    "model = Ridge()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mse, mae, r2 = mean_squared_error(y_test[:, 0], y_pred[:, 0]), mean_absolute_error(y_test[:, 0], y_pred[:, 0]), r2_score(y_test[:, 0], y_pred[:, 0])\n",
    "print(f\"Wind speed\\nMSE: {mse:.4f}, MAE: {mae:.4f}, R2: {r2:.4f}\")\n",
    "\n",
    "mse, mae, r2 = mean_squared_error(y_test[:, 1:], y_pred[:, 1:]), mean_absolute_error(y_test[:, 1:], y_pred[:, 1:]), r2_score(y_test[:, 1:], y_pred[:, 1:])\n",
    "print(f\"\\nWind direction\\nMSE: {mse:.4f}, MAE: {mae:.4f}, R2: {r2:.4f}\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
